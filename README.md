<b>ğŸ“ Automated Essay Scoring (AES) â€“ Kaggle Project</div</b>
<b>Automated Essay Scoring (AES) is an intelligent system designed to evaluate written essays using machine learning and deep learning techniques. This project focuses on developing a reliable scoring model using the Kaggle AES dataset, applying modern NLP preprocessing, feature engineering, and state-of-the-art neural architectures.
The goal is to create a scoring pipeline that performs consistently, reduces human bias, and delivers accurate, fast, and scalable evaluations of student writing.</b>
***
ğŸ“š Table of Contents

ğŸ“– Overview

ğŸ“ Repository Structure

ğŸ¯ Objectives

ğŸš€ Features

ğŸ› ï¸ Installation

ğŸ“Š Usage

ğŸ§¹ Data Preprocessing

ğŸ§  Models Used

ğŸ“ˆ Evaluation

ğŸ“‚ Dataset

ğŸ“š References

ğŸ“ License

âœ¨ Author

ğŸ“– Overview

Automated Essay Scoring (AES) is transforming the way learning assessments are conducted by improving the speed, consistency, and fairness of scoring. Manual grading is slow and labor-intensive, especially in areas with limited educational resources. AES applies machine learning and NLP techniques to automate the scoring process.

This project provides a comparative study of multiple AES models trained on one of the largest publicly accessible essay datasets aligned with modern educational standards.

Model Performance Summary
Model	Cohenâ€™s Kappa
Linear Regression	0.6540
XGBoost	0.7100
LightGBM (LGBM)	0.7210
LSTM	0.7710
BERT	0.7806

Deep learning models â€” especially LSTM and BERT â€” significantly outperform traditional machine learning methods in prediction accuracy and reproducibility.

The goal of this work is to propose a publicly available AES system that improves teacher workflow efficiency and provides students with fast, objective feedback.

ğŸ“ Repository Structure
â”œâ”€â”€ Dataset
â”‚   â”œâ”€â”€ train.csv
â”‚   â”œâ”€â”€ test.csv
â”‚
â”œâ”€â”€ Notebook
â”‚   â”œâ”€â”€ AES_model.ipynb
â”‚   â”œâ”€â”€ AES_inference.py
â”‚
â”œâ”€â”€ References
â”‚   â”œâ”€â”€ research_paper.pdf
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt

ğŸ¯ Objectives

Automate essay scoring using ML and NLP

Compare traditional and deep learning approaches

Extract linguistic & semantic features

Build train-ready and inference-ready scripts

Improve feedback speed for students

ğŸš€ Features

âœ” Full AES pipeline (preprocessing â†’ training â†’ prediction)
âœ” Multiple model comparisons
âœ” Deep learning support (LSTM, BERT)
âœ” Clean notebook + Python script
âœ” Requirements.txt for easy setup
âœ” MIT licensed

ğŸ› ï¸ Installation
1ï¸âƒ£ Clone the repository
git clone https://github.com/YourUsername/Automated-Essay-Scoring.git
cd Automated-Essay-Scoring

2ï¸âƒ£ Install dependencies
pip install -r requirements.txt

ğŸ“Š Usage
Run Jupyter Notebook
jupyter notebook


Open file:
Notebook/AES_model.ipynb

Run Python Inference Script
python Notebook/AES_inference.py

ğŸ§¹ Data Preprocessing

The pipeline includes:

Lowercasing

Punctuation removal

Stopword removal

Lemmatization

Tokenization

Word & sentence statistics

Readability metrics

TF-IDF feature extraction

ğŸ§  Models Used
Model Type	Description
Linear Regression	Baseline scoring model
RandomForest / XGBoost / LGBM	Strong for tabular + text stats
LSTM	Sequential deep learning model
BERT	Transformer-based, best semantic understanding
ğŸ“ˆ Evaluation

Primary Metric:

<div align="center">â­ Quadratic Weighted Kappa (QWK)</div>

Used in Kaggle AES competitions to measure agreement between model predictions and human graders.

ğŸ“‚ Dataset

Dataset contains:

Essay text

Essay set ID

Human-graded score

You must download the dataset from Kaggle:
ğŸ‘‰ Kaggle â†’ Automated Essay Scoring Dataset

ğŸ“š References

Kaggle AES Competition

NLP Educational Research

Included Research PDF in /References/

ğŸ“ License

This project is licensed under the MIT License.
See the LICENSE file.
